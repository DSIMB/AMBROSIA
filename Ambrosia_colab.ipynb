{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DSIMB/AMBROSIA/blob/main/Ambrosia_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_Bapdr6nMua"
      },
      "source": [
        "# Welcome to AMBROSIA: carbohydrate binding residues predictor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook initialization"
      ],
      "metadata": {
        "id": "mmScVOkg3TAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## Load AMBROSIA Github repository\n",
        "import os\n",
        "if os.getcwd() == \"/content\":\n",
        "    if os.path.exists(\"AMBROSIA/.git\"):\n",
        "        %cd AMBROSIA\n",
        "        !git pull\n",
        "    else:\n",
        "        !rm -rf AMBROSIA  # Remove if it's not a valid git repo\n",
        "        !git clone https://github.com/DSIMB/AMBROSIA.git\n",
        "        %cd AMBROSIA\n",
        "\n",
        "\n",
        "#if os.getcwd() == \"/content\":\n",
        "#    if os.path.exists(\"AMBROSIA\"):\n",
        "#        !rm -rf AMBROSIA  # Remove the existing directory\n",
        "#    !git clone https://github.com/DSIMB/AMBROSIA.git\n",
        "#    %cd AMBROSIA"
      ],
      "metadata": {
        "id": "lh9Rgt9v6o3g",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3KpmvGhoWj7",
        "collapsed": true,
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title ## Install necessary dependencies\n",
        "!pip install torch fair-esm ankh plotly py3Dmol matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MEVj1i0m2Xs"
      },
      "outputs": [],
      "source": [
        "#@title ## Import Necessary libraries\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import esm\n",
        "import ankh\n",
        "from plotly import graph_objects as go\n",
        "from google.colab import drive\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "import py3Dmol\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "from urllib.request import urlopen\n",
        "# drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read input protein sequence"
      ],
      "metadata": {
        "id": "en2tDNXfBSsb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NIZdZS9pWLM",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title ## Upload .fasta file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Access the uploaded file\n",
        "file_path = list(uploaded.keys())[0]\n",
        "print(f\"Uploaded file: {file_path}\")\n",
        "\n",
        "# Reading the uploaded file\n",
        "with open(file_path, 'r') as file:\n",
        "    sequence_name = \"\"\n",
        "    input_sequence = \"\"\n",
        "    for line in file:\n",
        "        line = line.strip()\n",
        "        if line.startswith(\">\"):\n",
        "            sequence_name = line[1:]  # Remove '>'\n",
        "        else:\n",
        "            input_sequence += line\n",
        "\n",
        "print(\"Sequence Name:\", sequence_name)\n",
        "print(\"Input Sequence:\", input_sequence)\n",
        "\n",
        "#sequence_name = \"Anti-sigma-W factor RsiW\"\n",
        "#input_sequence = \"\"\"\n",
        "#MGNNTGTILEIKGNKAIVMTNTCDFIAITRMPEMFVGQQVDLNNSAIKSKSNPLKYFAIAGMFVLILCSVLIYQLVKPSAVFAYVDVDINPSLELLIDKKANVIEVKTLNSDADALVKDIRLVNKSLTNAVKIIIKESQNKGFIRPDTKNAVLISASINPGKSISSAVSSEKILDVIVSDLQKTDFSIGAVSIKAEVVKVDPIERSEAVKNNISMGRYKLFEEITESDENIDIEKAKTEGLSKIIEEYETKEQEKTIASVDKDNSYKPVQDNKEILDKPKNSTTKDNPKVADNKKPENNNSQKYSNGNSNSSKSSAVKPNKAEDQFKASRSNSENNSSNNRDQSKNTNKKSSDEKKTLDQGSKPITTDDGTKSLNNKNNNKNNDEKPKNHPAKENKQENGNNNQQKSKEKNKK\n",
        "#\"\"\"\n",
        "\n",
        "input_sequence = input_sequence.replace('\\n', '')\n",
        "start_index = 1\n",
        "sequence_labels = [f\"{aa}{i}\" for i, aa in enumerate(input_sequence, start=start_index)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7PvwB7SqJ8A"
      },
      "source": [
        "# Generate embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1XQoVydqOPk",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title ## Generate ESM-2 embedding\n",
        "\n",
        "esm2_data = [(sequence_name, input_sequence)]\n",
        "\n",
        "# ESM-2\n",
        "model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
        "batch_converter = alphabet.get_batch_converter()\n",
        "model.eval()  # disables dropout for deterministic results\n",
        "\n",
        "batch_labels, batch_strs, batch_tokens = batch_converter(esm2_data)\n",
        "batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
        "\n",
        "# Extract per-residue representations (on CPU)\n",
        "with torch.no_grad():\n",
        "    results = model(batch_tokens, repr_layers=[33])\n",
        "esm2_embedding = results[\"representations\"][33][0,1:-1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## Generate Ankh embedding\n",
        "\n",
        "model, tokenizer = ankh.load_large_model()\n",
        "model.eval()\n",
        "\n",
        "ankh_data = [list(input_sequence)]\n",
        "outputs = tokenizer.batch_encode_plus(ankh_data,\n",
        "                                    add_special_tokens=True,\n",
        "                                    padding=True,\n",
        "                                    is_split_into_words=True,\n",
        "                                    return_tensors=\"pt\")\n",
        "with torch.no_grad():\n",
        "    embeddings = model(input_ids=outputs['input_ids'], attention_mask=outputs['attention_mask'])\n",
        "    ankh_embedding = embeddings.last_hidden_state[0, :-1]"
      ],
      "metadata": {
        "cellView": "form",
        "collapsed": true,
        "id": "Giivqg5jnov8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## Check resulting embedding dimensions\n",
        "\n",
        "print(esm2_embedding.shape, len(input_sequence), ankh_embedding.shape)\n",
        "assert esm2_embedding.shape[0] == len(input_sequence) == ankh_embedding.shape[0], \"Something went wrong during embedding generation\""
      ],
      "metadata": {
        "id": "geFbYUqQdJyD",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXzJC08xOKIU"
      },
      "source": [
        "\n",
        "# Perform predictions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## Upload model architecture & parameter paths\n",
        "from model.architecture import CNN\n",
        "\n",
        "# Define embedding sizes\n",
        "embedding_sizes = {\n",
        "    \"esm2\": esm2_embedding.shape[1] if esm2_embedding.shape[1] else 1280,\n",
        "    \"ankh\": ankh_embedding.shape[1] if ankh_embedding.shape[1] else 1536 # 1560\n",
        "}\n",
        "\n",
        "# Initialize models dictionary\n",
        "models = defaultdict(dict)\n",
        "results = defaultdict(dict)\n",
        "# Define paths to model parameters\n",
        "param_paths = {\n",
        "    \"ankh\": \"./model/weights/ankh/lr_5e-7_bs_64_modelconv_n512_d0.1_ks31_{}.pt\",\n",
        "    \"esm2\": \"./model/weights/esm2/lr_5e-7_bs_64_modelconv_n512_d0.1_ks31_{}.pt\",\n",
        "    #\"ankh\": \"/content/drive/MyDrive/ambrosia_models/models_yangfan/ambrosia_ankh_fold{}.pt\",\n",
        "    #\"esm2\": \"/content/drive/MyDrive/ambrosia_models/models_yangfan/ambrosia_esm2_fold{}.pt\"\n",
        "}"
      ],
      "metadata": {
        "id": "pQ0B7wtBv09U",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkjqHp5ow8wK",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title ## Upload model weights and perform predictions for each embedding\n",
        "# Load models and evaluate\n",
        "for model_type in [\"ankh\", \"esm2\"]:\n",
        "    for fold in range(5):\n",
        "        model = CNN(in_channels=embedding_sizes[model_type], kernel_size=31)\n",
        "        param_path = param_paths[model_type].format(fold)\n",
        "        model.load_state_dict(torch.load(param_path, map_location='cpu'))\n",
        "        model.eval()\n",
        "        models[model_type][fold] = model\n",
        "\n",
        "# Perform inference and store results\n",
        "with torch.no_grad():\n",
        "    for model_type in [\"ankh\", \"esm2\"]:\n",
        "        embedding = ankh_embedding if model_type == \"ankh\" else esm2_embedding\n",
        "        for fold in range(5):\n",
        "            model = models[model_type][fold]\n",
        "            logits = model(embedding.transpose(0, 1))\n",
        "            results[model_type][fold] = logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BC2G82pG2n-e"
      },
      "outputs": [],
      "source": [
        "#@title ## Calculate prediction average\n",
        "from model.calculate_and_plot_proba import calculate_probabilities_and_classes, plot_probabilities\n",
        "\n",
        "all_probs, ankh_probs, esm2_probs = calculate_probabilities_and_classes(results)\n",
        "\n",
        "# Calculate individual fold probabilities\n",
        "fold_probs_esm2 = [torch.sigmoid(torch.tensor(results[\"esm2\"][fold].numpy())).numpy() for fold in range(5)]\n",
        "fold_probs_ankh = [torch.sigmoid(torch.tensor(results[\"ankh\"][fold].numpy())).numpy() for fold in range(5)]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot predictions"
      ],
      "metadata": {
        "id": "z0A2va68_4Hg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot all probabilities\n",
        "plot_probabilities(sequence_labels, all_probs, esm2_probs, ankh_probs, fold_probs_esm2, fold_probs_ankh)"
      ],
      "metadata": {
        "id": "0PkHcTdo_3K2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkLgRX34-unb"
      },
      "source": [
        "# [Experimental] View on structure\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xC3yvuK2-spy"
      },
      "outputs": [],
      "source": [
        "# Function to read PDB file from URL\n",
        "def fetch_pdb_from_url(url):\n",
        "    response = urlopen(url)\n",
        "    pdb_data = response.read().decode('utf-8').splitlines()\n",
        "    return pdb_data\n",
        "\n",
        "# Prompt user for input method\n",
        "input_method = input(\"Enter 'upload' to upload a PDB file or 'url' to provide a URL: \").strip().lower()\n",
        "\n",
        "if input_method == 'upload':\n",
        "    uploaded = files.upload()\n",
        "    pdb_filename = next(iter(uploaded))\n",
        "    with open(pdb_filename, 'r') as file:\n",
        "        pdb_data = file.readlines()\n",
        "elif input_method == 'url':\n",
        "    pdb_url = input(\"Enter the URL of the PDB file: \").strip()\n",
        "    pdb_data = fetch_pdb_from_url(pdb_url)\n",
        "else:\n",
        "    raise ValueError(\"Invalid input method. Enter 'upload' or 'url'.\")\n",
        "# Modify B-factors in the PDB file\n",
        "new_pdb_data = []\n",
        "prob_index = 0\n",
        "last_res_id = None\n",
        "for line in pdb_data:\n",
        "    if line.startswith(\"ATOM\"):\n",
        "        res_id = line[22:26].strip()\n",
        "        if res_id != last_res_id:\n",
        "            if prob_index < len(all_probs):\n",
        "                new_line = line[:60] + f\"{all_probs[prob_index]*100:6.2f}\" + line[66:]\n",
        "                prob_index += 1\n",
        "            else:\n",
        "                new_line = line\n",
        "            last_res_id = res_id\n",
        "        else:\n",
        "            new_line = line[:60] + f\"{all_probs[prob_index-1]*100:6.2f}\" + line[66:]\n",
        "        new_pdb_data.append(new_line)\n",
        "    else:\n",
        "        new_pdb_data.append(line)\n",
        "\n",
        "# Save the modified structure to ensure line breaks are correct\n",
        "modified_pdb_filename = \"modified_structure.pdb\"\n",
        "with open(modified_pdb_filename, 'w') as file:\n",
        "    file.writelines('\\n'.join(new_pdb_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zw9Ry3KNHQt0"
      },
      "outputs": [],
      "source": [
        "# Lire le fichier PDB modifié\n",
        "with open(modified_pdb_filename, 'r') as file:\n",
        "    pdb_content = file.read()\n",
        "\n",
        "# Visualiser la structure avec Py3Dmol\n",
        "view = py3Dmol.view(width=800, height=600)\n",
        "view.addModel(pdb_content, \"pdb\")\n",
        "view.setStyle({'cartoon': {'color': 'grey'}})\n",
        "\n",
        "# Colorier les résidus en fonction des probabilités\n",
        "for i, prob in enumerate(all_probs):\n",
        "    if prob > 0.5:\n",
        "      resi = str(i + 1)\n",
        "      view.addStyle({'resi': resi}, {'stick': {'color': 'red'}})\n",
        "\n",
        "view.zoomTo()\n",
        "view.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "mmScVOkg3TAe",
        "W7PvwB7SqJ8A"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}